{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-10T03:51:51.057817Z",
     "iopub.status.busy": "2023-04-10T03:51:51.057261Z",
     "iopub.status.idle": "2023-04-10T03:51:51.067724Z",
     "shell.execute_reply": "2023-04-10T03:51:51.066042Z",
     "shell.execute_reply.started": "2023-04-10T03:51:51.057772Z"
    },
    "papermill": {
     "duration": 0.013332,
     "end_time": "2023-04-10T05:15:31.068664",
     "exception": false,
     "start_time": "2023-04-10T05:15:31.055332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Einleitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011944,
     "end_time": "2023-04-10T05:15:31.093169",
     "exception": false,
     "start_time": "2023-04-10T05:15:31.081225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Überblick über den Titanic Datensatz\n",
    "\n",
    "Der Titanic Datensatz ist ein berühmter Datensatz im Bereich des maschinellen Lernens und der Datenanalyse, der Daten über die Passagiere an Bord der Titanic und ihren Überlebensstatus enthält. Er besteht aus einem Trainingsdatensatz mit 891 Beobachtungen und einem Testdatensatz mit 418 Beobachtungen. Ziel ist es, das Überleben der Passagiere im Testdatensatz auf der Grundlage der Variablen im Trainingsdatensatz vorherzusagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012487,
     "end_time": "2023-04-10T05:15:31.117915",
     "exception": false,
     "start_time": "2023-04-10T05:15:31.105428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importieren der Bibliotheken\n",
    "Zunächst importieren wir die notwendigen Bibliotheken, die wir im Laufe dieses Notebooks verwenden werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T08:08:34.858496Z",
     "iopub.status.busy": "2023-09-20T08:08:34.857991Z"
    },
    "papermill": {
     "duration": 1.933327,
     "end_time": "2023-04-10T05:15:33.065575",
     "exception": false,
     "start_time": "2023-04-10T05:15:31.132248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Manipulation Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization Libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score ,precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import  classification_report, confusion_matrix\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012053,
     "end_time": "2023-04-10T05:15:33.090127",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.078074",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Laden des Datensatzes\n",
    "\n",
    "In diesem Abschnitt werden wir den Titanic Datensatz in das Notebook laden. Der Datensatz ist in zwei CSV-Dateien gespeichert, eine für die Trainingsdaten und eine für die Testdaten. Wir verwenden die Pandas-Bibliothek, um die CSV-Dateien in Dataframes zu laden, die wir bearbeiten und untersuchen können. Nach dem Laden können wir damit beginnen, die Daten zu untersuchen und sie für die Modellierung mit maschinellem Lernen vorzubereiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.044625,
     "end_time": "2023-04-10T05:15:33.147301",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.102676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading the train data\n",
    "train_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "\n",
    "# Reading the test data\n",
    "test = pd.read_csv(\"/kaggle/input/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012623,
     "end_time": "2023-04-10T05:15:33.173307",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.160684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Verstehen der Variablen\n",
    "\n",
    "Bevor wir mit der Analyse des Titanic Datensatzes beginnen können, ist es wichtig zu verstehen, wofür die einzelnen Variablen stehen. Der Datensatz enthält die folgenden Variablen:\n",
    "\n",
    "PassengerId: Eine eindeutige Kennung für jeden Passagier.\n",
    "\n",
    "Survived: Ob der Passagier überlebt hat oder nicht (0 = No, 1 = Yes).\n",
    "\n",
    "Pclass: Die Passagierklasse (1 = 1st class, 2 = 2nd class, 3 = 3rd class).\n",
    "\n",
    "Name: Der Name des Passagiers.\n",
    "\n",
    "Sex: Das Geschlecht des Fahrgastes.\n",
    "\n",
    "Age: Das Alter des Fahrgastes in Jahren. Bei Kleinkindern werden Bruchteile angegeben.\n",
    "\n",
    "SibSp: Die Anzahl der Geschwister/Ehegatten an Bord der Titanic.\n",
    "\n",
    "Parch: Die Anzahl der Eltern/Kinder an Bord der Titanic.\n",
    "\n",
    "Ticket: Die Ticketnummer des Passagiers.\n",
    "\n",
    "Fare: Der vom Fahrgast bezahlte Fahrpreis.\n",
    "\n",
    "Cabin: Die Kabinennummer des Passagiers (falls vorhanden).\n",
    "\n",
    "Embarked: Der Hafen der Einschiffung (C = Cherbourg, Q = Queenstown, S = Southampton)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012319,
     "end_time": "2023-04-10T05:15:33.198302",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.185983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Datenexploration und -aufbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.046613,
     "end_time": "2023-04-10T05:15:33.257935",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.211322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We use method head() to show the first 5 rows\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.030709,
     "end_time": "2023-04-10T05:15:33.301481",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.270772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.021639,
     "end_time": "2023-04-10T05:15:33.335971",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.314332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (test.shape)\n",
    "print (train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012692,
     "end_time": "2023-04-10T05:15:33.361774",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.349082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Wie wir oben sehen, haben wir 11 Attribute und 418 Datensätze im Testdatensatz, aber wir haben 12 Attribute und 891 Datensätze im Trainingsdatensatz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.061946,
     "end_time": "2023-04-10T05:15:33.436649",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.374703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012851,
     "end_time": "2023-04-10T05:15:33.462790",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.449939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Der obige Befehl `df.describe()` stellt statistische Eigenschaften in vertikaler Form dar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.030604,
     "end_time": "2023-04-10T05:15:33.506690",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.476086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for duplicated rows in train data\n",
    "train_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.025404,
     "end_time": "2023-04-10T05:15:33.545609",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.520205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for null values in train data\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.028493,
     "end_time": "2023-04-10T05:15:33.588009",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.559516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for duplicated rows in test data\n",
    "test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.026606,
     "end_time": "2023-04-10T05:15:33.628695",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.602089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for null values in test data\n",
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.026564,
     "end_time": "2023-04-10T05:15:33.669025",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.642461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The number of men who survived\n",
    "train_df[train_df['Sex']=='male']['Survived'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.025046,
     "end_time": "2023-04-10T05:15:33.708357",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.683311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The number of women who survived\n",
    "train_df[train_df['Sex']=='female']['Survived'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013601,
     "end_time": "2023-04-10T05:15:33.736657",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.723056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Der folgende Code verwendet die Seaborn-Bibliothek, um Diagramme zu erstellen, die die Anzahl der überlebenden und nicht überlebenden Passagiere für jede der Spalten `Sex`, `Embarked`, `Pclass`, `SibSp` und `Parch` anzeigen.\n",
    "\n",
    "In einer Schleife wird der Vorgang für jede angegebene Spalte in der Liste ['Sex', 'Embarked', 'Pclass', 'SibSp', 'Parch'] wiederholt.\n",
    "\n",
    "Zum Zeichnen des Diagramms wird die Funktion \"countplot\" von Seaborn verwendet. Diese Funktion zeigt die Anzahl der Fälle in jeder Kategorie für die verschiedenen Werte der angegebenen Spalte (z. B. Geschlecht oder Ticketklasse) an, zusammen mit der charakteristischen Farbe für jede Kategorie (überlebt und nicht überlebt). Mit anderen Worten, die Anzahl der überlebenden und nicht überlebenden Passagiere wird für jeden unterschiedlichen Wert der angegebenen Spalte angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.865737,
     "end_time": "2023-04-10T05:15:34.616269",
     "exception": false,
     "start_time": "2023-04-10T05:15:33.750532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for column_name in ['Sex','Embarked','Pclass', 'SibSp', 'Parch']:\n",
    "    print(column_name)\n",
    "    sns.countplot(data=train_df, x=column_name, hue='Survived')\n",
    "    plt.show()\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.23286,
     "end_time": "2023-04-10T05:15:34.864428",
     "exception": false,
     "start_time": "2023-04-10T05:15:34.631568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.histplot(train_df['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016262,
     "end_time": "2023-04-10T05:15:34.896728",
     "exception": false,
     "start_time": "2023-04-10T05:15:34.880466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Zum Zeichnen des Histogramms wird die Funktion `histplot` von Seaborn verwendet. Diese Funktion zeigt die Häufigkeitsverteilung der Spalte `Alter` an, d. h. die Anzahl der Passagiere in jeder Altersgruppe.\n",
    "\n",
    "Anhand des Histogramms lassen sich Muster und Trends in der Altersverteilung der Fahrgäste im Datensatz `train_df` erkennen, z. B. die häufigste Altersgruppe oder das Auftreten von Ausreißern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.028169,
     "end_time": "2023-04-10T05:15:34.940889",
     "exception": false,
     "start_time": "2023-04-10T05:15:34.912720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the mean age of male passengers in the 'train_df' dataset.\n",
    "mean_male = train_df[train_df['Sex']=='male']['Age'].mean()\n",
    "mean_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.03064,
     "end_time": "2023-04-10T05:15:34.988739",
     "exception": false,
     "start_time": "2023-04-10T05:15:34.958099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the mean age of بثmale passengers in the 'train_df' dataset.\n",
    "mean_female = train_df[train_df['Sex']=='female']['Age'].mean()\n",
    "mean_female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01598,
     "end_time": "2023-04-10T05:15:35.020931",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.004951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Wie wir gesehen haben, gibt es einen Unterschied zwischen dem Mittelwert der Männer und dem Mittelwert der Frauen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015818,
     "end_time": "2023-04-10T05:15:35.053031",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.037213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Im nachstehenden Code wird die Funktion `fillna` verwendet, um die fehlenden Werte in der Spalte `Age` für männliche und weibliche Fahrgäste mit den Werten `mean_male` bzw. `mean_female` zu füllen.\n",
    "\n",
    "Dazu werden zunächst die Zeilen im `train_df`-Datensatz ausgewählt, in denen `Sex` `male` ist, indem die Bedingung `train_df['Sex']=='male'` verwendet wird. Dann werden für diese ausgewählten Zeilen die fehlenden Werte in der Spalte `Age` mit `mean_male` aufgefüllt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.028027,
     "end_time": "2023-04-10T05:15:35.097261",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.069234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.loc[train_df['Sex']=='male', 'Age'] = train_df[train_df['Sex']=='male']['Age'].fillna(value=mean_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.028012,
     "end_time": "2023-04-10T05:15:35.142401",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.114389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.loc[train_df['Sex']=='female', 'Age'] = train_df[train_df['Sex']=='female']['Age'].fillna(value=mean_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.033629,
     "end_time": "2023-04-10T05:15:35.192957",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.159328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016411,
     "end_time": "2023-04-10T05:15:35.226408",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.209997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Wie wir gesehen haben, gibt es keine Nullwerte in der Spalte `Age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.027252,
     "end_time": "2023-04-10T05:15:35.269291",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.242039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropping some unimportant features\n",
    "train_df.drop(['PassengerId','SibSp','Parch','Ticket','Cabin','Name'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.032195,
     "end_time": "2023-04-10T05:15:35.318456",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.286261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.036932,
     "end_time": "2023-04-10T05:15:35.373429",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.336497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion `dropna` wird verwendet, um alle Zeilen im `train_df` Datensatz zu entfernen, die fehlende Werte (d. h. NaN-Werte) enthalten. Der Parameter `inplace=True` wird verwendet, um den Datensatz `train_df` direkt zu ändern, anstatt einen neuen geänderten Datensatz zurückzugeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.027027,
     "end_time": "2023-04-10T05:15:35.456339",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.429312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015968,
     "end_time": "2023-04-10T05:15:35.488663",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.472695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Wie wir oben sehen, gibt es keine Nullwerte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.026597,
     "end_time": "2023-04-10T05:15:35.531979",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.505382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.replace({'female':0,'male':1},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018675,
     "end_time": "2023-04-10T05:15:35.567675",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.549000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Die Funktion `replace` wird verwendet, um die Werte `female` und `male` im Datensatz `train_df` durch 0 bzw. 1 zu ersetzen. Dazu wird ein Wörterbuch mit den Schlüsseln `female` und `male` und den entsprechenden Werten 0 und 1 an die Funktion `replace` übergeben. Der Parameter `inplace=True` wird verwendet, um den Datensatz `train_df` direkt zu ändern, anstatt einen neuen geänderten Datensatz zurückzugeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.031998,
     "end_time": "2023-04-10T05:15:35.616772",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.584774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df,columns=['Embarked'],prefix='Embarked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016274,
     "end_time": "2023-04-10T05:15:35.649618",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.633344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Die Funktion `get_dummies` von Pandas wird verwendet, um Dummy-Variablen für die Spalte `Embarked` im Datensatz `train_df` zu erstellen. Dazu werden der Datensatz `train_df` und die Spalte `Embarked` an den Parameter `columns` der Funktion `get_dummies` übergeben. Der Parameter `prefix` wird verwendet, um den Spaltennamen der resultierenden Dummy-Variablen das Präfix `Embarked_` hinzuzufügen.\n",
    "\n",
    "Der resultierende Datensatz `train_df` enthält nun die neuen Spalten `Embarked_C`, `Embarked_Q` und `Embarked_S` mit binären Werten (0 oder 1), die angeben, ob ein Passagier vom entsprechenden Hafen aus eingeschifft wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.033464,
     "end_time": "2023-04-10T05:15:35.699445",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.665981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017574,
     "end_time": "2023-04-10T05:15:35.733988",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.716414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Aufsplitten der Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.035875,
     "end_time": "2023-04-10T05:15:35.786757",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.750882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into x and y\n",
    "x = train_df.drop('Survived',axis =1)\n",
    "y = train_df['Survived']\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016622,
     "end_time": "2023-04-10T05:15:35.820747",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.804125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Dieser Code standardisiert die Werte der Spalten `Age` und `Fare` im `x` Datenframe mit Hilfe des StandardScaler aus der scikit-learn-Bibliothek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.030976,
     "end_time": "2023-04-10T05:15:35.868405",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.837429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select numerical columns\n",
    "num_cols = ['Age', 'Fare']\n",
    "\n",
    "# Create scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler on selected columns\n",
    "scaler.fit(x[num_cols])\n",
    "\n",
    "# Transform selected columns with scaler\n",
    "x[num_cols] = scaler.transform(x[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.03042,
     "end_time": "2023-04-10T05:15:35.915940",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.885520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split train data into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017124,
     "end_time": "2023-04-10T05:15:35.950248",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.933124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modelbildung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3.179313,
     "end_time": "2023-04-10T05:15:39.146880",
     "exception": false,
     "start_time": "2023-04-10T05:15:35.967567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'XGBClassifier':XGBClassifier(),\n",
    "    'GradientBoostingClassifier':GradientBoostingClassifier(),\n",
    "    'AdaBoostClassifier':AdaBoostClassifier()\n",
    "    \n",
    "}\n",
    "\n",
    "# Train and evaluate each model using cross-validation\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, x_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"{name} accuracy: {scores.mean():.3f} +/- {scores.std():.3f}\")\n",
    "    \n",
    "    # Fit the model to the full training set and make predictions on the test set\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(f\"Precision: {prec:.3f}\")\n",
    "    print(f\"Recall: {rec:.3f}\")\n",
    "    print(f\"F1-score: {f1:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017955,
     "end_time": "2023-04-10T05:15:39.182692",
     "exception": false,
     "start_time": "2023-04-10T05:15:39.164737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Nach dem Vergleich der Genauigkeit verschiedener Modelle stellten wir fest, dass das GradientBoostingClassifier-Modell die höchste Genauigkeit aufwies.\n",
    "\n",
    "Ich werde sie also verwenden, um eine Vorhersage für die Testmenge zu treffen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.489857,
     "end_time": "2023-04-10T05:15:39.691052",
     "exception": false,
     "start_time": "2023-04-10T05:15:39.201195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gbc= GradientBoostingClassifier()\n",
    "scores = cross_val_score(gbc, x_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"{gbc} accuracy: {scores}\")\n",
    "    \n",
    "# Fit the model to the full training set and make predictions on the test set\n",
    "gbc.fit(x_train, y_train)\n",
    "y_pred = gbc.predict(x_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print (acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017191,
     "end_time": "2023-04-10T05:15:39.725978",
     "exception": false,
     "start_time": "2023-04-10T05:15:39.708787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Vorbereitung der Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.03786,
     "end_time": "2023-04-10T05:15:39.781651",
     "exception": false,
     "start_time": "2023-04-10T05:15:39.743791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show the first 5 columns \n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.035507,
     "end_time": "2023-04-10T05:15:39.835749",
     "exception": false,
     "start_time": "2023-04-10T05:15:39.800242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill the null values in the age column\n",
    "mean_male_test = test[test['Sex']=='male']['Age'].mean()\n",
    "mean_female_test = test[test['Sex']=='female']['Age'].mean()\n",
    "test.loc[test['Sex']=='male', 'Age'] = test[test['Sex']=='male']['Age'].fillna(value=mean_male_test)\n",
    "test.loc[test['Sex']=='female', 'Age'] = test[test['Sex']=='female']['Age'].fillna(value=mean_female_test)\n",
    "\n",
    "# Fill the null values in the Fare column\n",
    "test['Fare'].fillna(test['Fare'].median(), inplace = True)\n",
    "\n",
    "# Dropping some unimportant features\n",
    "test.drop(['SibSp','Parch','Ticket','Cabin','Name'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.031446,
     "end_time": "2023-04-10T05:15:39.884234",
     "exception": false,
     "start_time": "2023-04-10T05:15:39.852788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017798,
     "end_time": "2023-04-10T05:15:39.920078",
     "exception": false,
     "start_time": "2023-04-10T05:15:39.902280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Erneut keine Nullwerte zu entdecken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.030756,
     "end_time": "2023-04-10T05:15:39.968560",
     "exception": false,
     "start_time": "2023-04-10T05:15:39.937804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert string values to numeric by replace the female and male by 0 and 1\n",
    "test.replace({'female':0,'male':1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.033491,
     "end_time": "2023-04-10T05:15:40.020500",
     "exception": false,
     "start_time": "2023-04-10T05:15:39.987009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using one hot encoder to convert string values \n",
    "test = pd.get_dummies(test,columns=['Embarked'],prefix='Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.0344,
     "end_time": "2023-04-10T05:15:40.073177",
     "exception": false,
     "start_time": "2023-04-10T05:15:40.038777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit scaler on numeric columns\n",
    "scaler.fit(test[num_cols])\n",
    "\n",
    "# Transform numeric columns with scaler\n",
    "test[num_cols] = scaler.transform(test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.033945,
     "end_time": "2023-04-10T05:15:40.125845",
     "exception": false,
     "start_time": "2023-04-10T05:15:40.091900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.028645,
     "end_time": "2023-04-10T05:15:40.171971",
     "exception": false,
     "start_time": "2023-04-10T05:15:40.143326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store PassengerId column in a separate variable\n",
    "\n",
    "PassengerId = test['PassengerId']\n",
    "\n",
    "# Drop PassengerId column from the test set\n",
    "test.drop('PassengerId',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019944,
     "end_time": "2023-04-10T05:15:40.209965",
     "exception": false,
     "start_time": "2023-04-10T05:15:40.190021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Vorhersagen und Einreichung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.03103,
     "end_time": "2023-04-10T05:15:40.259509",
     "exception": false,
     "start_time": "2023-04-10T05:15:40.228479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate predictions for the test data using GradientBoostingClassifier \n",
    "test_pred = gbc.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017475,
     "end_time": "2023-04-10T05:15:40.295098",
     "exception": false,
     "start_time": "2023-04-10T05:15:40.277623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Erstellung einer Datei zum Hochladen mit der Spalte `PassengerId` und den vorhergesagten Überlebensergebnissen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.027477,
     "end_time": "2023-04-10T05:15:40.341350",
     "exception": false,
     "start_time": "2023-04-10T05:15:40.313873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId': PassengerId, 'Survived': test_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.032179,
     "end_time": "2023-04-10T05:15:40.391292",
     "exception": false,
     "start_time": "2023-04-10T05:15:40.359113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
